{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import geopy as gp\n",
    "import pandas as pd\n",
    "from geopy.geocoders import Nominatim\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from src.config import PROCESSED_DATA_DIR, RAW_DATA_DIR, INTERIM_DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train.drop(columns=['coarse', 'medium', 'fine']).to_csv(INTERIM_DATA_DIR / 'train/train.csv', index = False)\n",
    "df_train = pd.read_csv(INTERIM_DATA_DIR / 'pos_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as func\n",
    "from torchvision import datasets, transforms\n",
    "from src.base.OSVImageDataset import OSVImageDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import ViTImageProcessor\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "KERNEL_SIZE = 16 #16x16 patch\n",
    "CHANNELS = 3 #rgb\n",
    "RESIZE = 224\n",
    "EMBED_DIM = CHANNELS * KERNEL_SIZE ** 2\n",
    "NUM_PATCHES = ((RESIZE + 0 - KERNEL_SIZE)//KERNEL_SIZE + 1) ** 2\n",
    "COARSE = int(df_train['coarse_i'].values.max()) + 1\n",
    "MEDIUM = int(df_train['medium_i'].values.max()) + 1\n",
    "FINE = int(df_train['fine_i'].values.max()) + 1\n",
    "MODEL_NAME = 'google/vit-base-patch16-224-in21k'\n",
    "\n",
    "#Using values the ViT was trained on\n",
    "processor = ViTImageProcessor.from_pretrained(MODEL_NAME, do_rescale = False, return_tensors = 'pt')\n",
    "\n",
    "image_mean, image_std = processor.image_mean, processor.image_std\n",
    "size = processor.size[\"height\"]\n",
    "\n",
    "normalize = v2.Normalize(mean=image_mean, std=image_std)\n",
    "\n",
    "train_transform = v2.Compose([\n",
    "      v2.Resize((processor.size[\"height\"], processor.size[\"width\"])),\n",
    "      #v2.RandomHorizontalFlip(0.4),\n",
    "      #v2.RandomVerticalFlip(0.1),\n",
    "      #v2.RandomApply(transforms=[v2.RandomRotation(degrees=(0, 90))], p=0.5),\n",
    "      #v2.RandomApply(transforms=[v2.ColorJitter(brightness=.3, hue=.1)], p=0.3),\n",
    "      #v2.RandomApply(transforms=[v2.GaussianBlur(kernel_size=(5, 9))], p=0.3),\n",
    "      normalize\n",
    " ])\n",
    "\n",
    "test_transform = v2.Compose([\n",
    "    v2.Resize((processor.size[\"height\"], processor.size[\"width\"])),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "train_dataset = OSVImageDataset(annotations_df = df_train, img_dir=INTERIM_DATA_DIR / 'train', transform=train_transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/18846 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from safetensors.torch import save_file\n",
    "import gc\n",
    "import time\n",
    "\n",
    "start = time.perf_counter()\n",
    "batch_num = 0\n",
    "for images, labels in tqdm(train_dataloader):\n",
    "    save_file(tensors={'images':images, 'labels': labels}, filename=PROCESSED_DATA_DIR / 'tensors'/ f'batch_{batch_num}.safetensors')\n",
    "    batch_num+=1\n",
    "    if batch_num == 1:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 224, 224])\n",
      "torch.Size([128, 3])\n",
      "concat perf:0.07821529998909682\n"
     ]
    }
   ],
   "source": [
    "from safetensors import safe_open\n",
    "\n",
    "start = time.perf_counter()\n",
    "images_buffer = []\n",
    "labels_buffer = []\n",
    "for i in range(2):\n",
    "    with safe_open(f\"test_{i}.safetensors\", framework='pt', device=device.__str__()) as t:\n",
    "        images = t.get_tensor('images')\n",
    "        labels = t.get_tensor('labels')\n",
    "        #print(np.shape(images))\n",
    "        images_buffer.append(images)\n",
    "        labels_buffer.append(labels)\n",
    "\n",
    "batch_imgs = torch.cat(images_buffer, dim=0) \n",
    "batch_labels = torch.cat(labels_buffer, dim=0) \n",
    "end = time.perf_counter()  \n",
    "print(np.shape(batch_imgs))\n",
    "print(np.shape(batch_labels))\n",
    "print(f'concat perf:{end - start}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import decode_image, read_file\n",
    "from safetensors import safe_open\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "class OSVProcessedImages(Dataset):\n",
    "    def __init__(self, batch_dir):\n",
    "        self.batch_files = sorted(os.listdir(batch_dir))\n",
    "        self.batch_dir = batch_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.batch_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_path = os.path.join(self.batch_dir, self.batch_files[idx])\n",
    "        with safe_open(batch_path, framework='pt', device=device.__str__()) as t:\n",
    "            images = t.get_tensor('images')\n",
    "            labels = t.get_tensor('labels')\n",
    "\n",
    "        return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "torch.Size([128, 3, 224, 224])\n",
      "torch.Size([128, 3])\n",
      "concat perf:0.0538624000037089\n"
     ]
    }
   ],
   "source": [
    "batch_d = OSVProcessedImages(batch_dir=INTERIM_DATA_DIR / 'temp')\n",
    "batch_loader = DataLoader(batch_d, batch_size=2, shuffle=False)\n",
    "start = time.perf_counter()\n",
    "for images, labels in batch_loader:\n",
    "    print(images.is_contiguous())\n",
    "    print(np.shape(images.reshape(-1, CHANNELS, RESIZE, RESIZE)))\n",
    "    print(np.shape(labels.reshape(-1, CHANNELS)))\n",
    "end = time.perf_counter()  \n",
    "print(f'concat perf:{end - start}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating zip files for Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 83742/1206098 [00:06<01:33, 11972.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressing chunk 1 with 83866 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83866/83866 [06:38<00:00, 210.49it/s]t/s]\n",
      " 14%|█▍        | 166408/1206098 [06:51<01:26, 11972.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressing chunk 2 with 82844 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82844/82844 [07:35<00:00, 181.79it/s]it/s]\n",
      " 21%|██        | 250786/1206098 [14:45<03:08, 5064.97it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressing chunk 3 with 84223 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84223/84223 [07:27<00:00, 188.04it/s]t/s]\n",
      " 28%|██▊       | 335454/1206098 [22:35<03:32, 4094.31it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressing chunk 4 with 84596 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84596/84596 [07:43<00:00, 182.36it/s]t/s]\n",
      " 35%|███▍      | 418702/1206098 [30:34<02:17, 5743.70it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressing chunk 5 with 83200 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83200/83200 [07:36<00:00, 182.42it/s]t/s]\n",
      " 42%|████▏     | 502449/1206098 [38:19<01:09, 10097.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressing chunk 6 with 83865 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83865/83865 [07:19<00:00, 190.88it/s]it/s]\n",
      " 49%|████▊     | 585931/1206098 [45:50<01:19, 7826.97it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressing chunk 7 with 83922 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83922/83922 [07:49<00:00, 178.90it/s]t/s]\n",
      " 56%|█████▌    | 669919/1206098 [53:54<01:17, 6903.53it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressing chunk 8 with 84027 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84027/84027 [07:42<00:00, 181.61it/s]t/s]\n",
      " 62%|██████▏   | 753174/1206098 [1:01:50<01:12, 6290.37it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressing chunk 9 with 83117 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83117/83117 [07:30<00:00, 184.54it/s]7it/s]\n",
      " 69%|██████▉   | 837104/1206098 [1:09:33<00:50, 7302.62it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressing chunk 10 with 83721 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83721/83721 [08:01<00:00, 173.72it/s]2it/s]\n",
      " 76%|███████▋  | 921369/1206098 [1:17:47<00:38, 7318.06it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressing chunk 11 with 84320 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84320/84320 [07:38<00:00, 183.86it/s]6it/s]\n",
      " 83%|████████▎ | 1004910/1206098 [1:25:37<00:26, 7673.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressing chunk 12 with 83473 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83473/83473 [08:01<00:00, 173.51it/s]70it/s]\n",
      " 90%|█████████ | 1088022/1206098 [1:33:52<00:20, 5704.58it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressing chunk 13 with 83362 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83362/83362 [07:52<00:00, 176.34it/s]58it/s]\n",
      " 97%|█████████▋| 1172470/1206098 [1:42:03<00:06, 5068.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressing chunk 14 with 84577 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84577/84577 [07:32<00:00, 186.76it/s]76it/s]\n",
      "100%|██████████| 1206098/1206098 [1:49:41<00:00, 183.25it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressing final chunk 15 with 32985 images...\n",
      "All chunks created successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import math\n",
    "from zipfile import ZipFile\n",
    "\n",
    "# Define paths\n",
    "IMAGE_FOLDER = INTERIM_DATA_DIR / 'train'  # Replace with the folder containing images\n",
    "CSV_FILE = INTERIM_DATA_DIR / 'train.csv'  # CSV file with the image IDs\n",
    "OUTPUT_DIR = PROCESSED_DATA_DIR / 'train'  # Folder where compressed chunks will be saved\n",
    "CHUNK_SIZE_GB = 4  # Target size of each chunk in GB\n",
    "IMAGE_EXTENSION = '.jpg'  # Image file format\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Read image IDs from the CSV file\n",
    "df = pd.read_csv(CSV_FILE)\n",
    "image_ids = df['id'].astype(str).tolist()  # Ensure IDs are strings\n",
    "\n",
    "# Function to calculate size of images\n",
    "def get_image_size(image_path):\n",
    "    return os.path.getsize(image_path) / (1024 ** 3)  # Convert bytes to GB\n",
    "\n",
    "# Create chunks\n",
    "current_chunk = 1\n",
    "current_chunk_size = 0\n",
    "current_images = []\n",
    "\n",
    "for img_id in tqdm(image_ids):\n",
    "    img_path = os.path.join(IMAGE_FOLDER, f\"{img_id}{IMAGE_EXTENSION}\")\n",
    "    if os.path.exists(img_path):\n",
    "        img_size = get_image_size(img_path)\n",
    "        # Check if adding this image exceeds the chunk size\n",
    "        if current_chunk_size + img_size > CHUNK_SIZE_GB:\n",
    "            # Compress the current chunk\n",
    "            chunk_name = os.path.join(OUTPUT_DIR, f\"train_{current_chunk}.zip\")\n",
    "            print(f\"Compressing chunk {current_chunk} with {len(current_images)} images...\")\n",
    "            with ZipFile(chunk_name, 'w') as zipf:\n",
    "                for image in tqdm(current_images):\n",
    "                    zipf.write(image, os.path.basename(image))  # Add image to the zip\n",
    "            # Reset for the next chunk\n",
    "            current_chunk += 1\n",
    "            current_chunk_size = 0\n",
    "            current_images = []\n",
    "        \n",
    "        # Add image to the current chunk\n",
    "        current_images.append(img_path)\n",
    "        current_chunk_size += img_size\n",
    "    else:\n",
    "        print(f\"Warning: {img_path} not found.\")\n",
    "\n",
    "# Compress the remaining images in the last chunk\n",
    "if current_images:\n",
    "    chunk_name = os.path.join(OUTPUT_DIR, f\"train_{current_chunk}.zip\")\n",
    "    print(f\"Compressing final chunk {current_chunk} with {len(current_images)} images...\")\n",
    "    with ZipFile(chunk_name, 'w') as zipf:\n",
    "        for image in current_images:\n",
    "            zipf.write(image, os.path.basename(image))\n",
    "\n",
    "print(\"All chunks created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting G:\\Work\\DS\\where-am-i\\data\\processed\\train\\train_15.zip...\n",
      "All images extracted successfully!\n"
     ]
    }
   ],
   "source": [
    "#from google.colab import drive\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Mount Google Drive\n",
    "#drive.mount('/content/drive')\n",
    "\n",
    "# Define paths\n",
    "DRIVE_FOLDER = PROCESSED_DATA_DIR / 'train'  # Folder where chunks are stored\n",
    "EXTRACTION_FOLDER = PROCESSED_DATA_DIR / 't'  # Folder to extract images\n",
    "\n",
    "os.makedirs(EXTRACTION_FOLDER, exist_ok=True)\n",
    "\n",
    "# List chunks\n",
    "chunks = [f for f in os.listdir(DRIVE_FOLDER) if f == 'train_15.zip']\n",
    "\n",
    "# Extract all chunks\n",
    "for chunk in chunks:\n",
    "    chunk_path = os.path.join(DRIVE_FOLDER, chunk)\n",
    "    print(f\"Extracting {chunk_path}...\")\n",
    "    shutil.unpack_archive(chunk_path, EXTRACTION_FOLDER)\n",
    "\n",
    "print(\"All images extracted successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "where-am-i-s7vJJwrF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
